{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# Load data\n",
    "data_path = r'C:\\Users\\Subways-Sun\\OneDrive\\Documents\\GitHub\\sodium-ion-batteries\\data_annotated\\search_20241106-223705_sodium+ion+battery+anode-sodium+ion+battery+cathode-sodium+ion+battery+electrode_annotated_rephrased.json'\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Prepare data\n",
    "texts = []\n",
    "labels_raw = []\n",
    "for i in data:\n",
    "    texts.append(i[\"text\"])\n",
    "    labels_raw.append(i[\"label_int\"])\n",
    "\n",
    "labels = []\n",
    "for i in labels_raw:\n",
    "    if i == 0:\n",
    "        labels.append(1)\n",
    "    elif i == 1:\n",
    "        labels.append(0)\n",
    "\n",
    "# Split data\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    texts,\n",
    "    labels,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = Dataset.from_dict({\n",
    "    'text': train_texts,\n",
    "    'labels': train_labels\n",
    "})\n",
    "val_dataset = Dataset.from_dict({\n",
    "    'text': val_texts,\n",
    "    'labels': val_labels\n",
    "})\n",
    "raw_datasets = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': val_dataset\n",
    "})\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'labels'],\n",
      "        num_rows: 320\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'labels'],\n",
      "        num_rows: 80\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(raw_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f27e9e551e494b41a0bf68542c1311a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/320 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc1138f355524704ba57df23f9b97609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/80 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "483280702d144a9ea57cbdd9d87feca0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7902, 'grad_norm': 3.9231011867523193, 'learning_rate': 9e-07, 'epoch': 0.25}\n",
      "{'loss': 0.842, 'grad_norm': 0.000405534083256498, 'learning_rate': 1.9e-06, 'epoch': 0.5}\n",
      "{'loss': 1.3617, 'grad_norm': 4.130080699920654, 'learning_rate': 2.8000000000000003e-06, 'epoch': 0.75}\n",
      "{'loss': 1.7605, 'grad_norm': 22.6730899810791, 'learning_rate': 3.8e-06, 'epoch': 1.0}\n",
      "\n",
      "Epoch 1/10\n",
      "Training Loss: 1.7605\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e353f9048c294c9dae388002e381aa62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6691043376922607, 'eval_accuracy': 0.825, 'eval_runtime': 0.2846, 'eval_samples_per_second': 281.089, 'eval_steps_per_second': 35.136, 'epoch': 1.0}\n",
      "{'loss': 0.7248, 'grad_norm': 24.809722900390625, 'learning_rate': 4.800000000000001e-06, 'epoch': 1.25}\n",
      "{'loss': 0.8498, 'grad_norm': 27.25240707397461, 'learning_rate': 5.7000000000000005e-06, 'epoch': 1.5}\n",
      "{'loss': 0.6623, 'grad_norm': 48.782081604003906, 'learning_rate': 6.700000000000001e-06, 'epoch': 1.75}\n",
      "{'loss': 0.2753, 'grad_norm': 2.9203381538391113, 'learning_rate': 7.7e-06, 'epoch': 2.0}\n",
      "\n",
      "Epoch 2/10\n",
      "Training Loss: 0.2753\n",
      "Evaluation Loss: 1.6691\n",
      "Evaluation Accuracy: 0.8250\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2313d76905c8463485ce1cfe9486783e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7481721639633179, 'eval_accuracy': 0.8625, 'eval_runtime': 0.2796, 'eval_samples_per_second': 286.174, 'eval_steps_per_second': 35.772, 'epoch': 2.0}\n",
      "{'loss': 0.3848, 'grad_norm': 0.24446101486682892, 'learning_rate': 8.7e-06, 'epoch': 2.25}\n",
      "{'loss': 0.1532, 'grad_norm': 0.8036653995513916, 'learning_rate': 9.7e-06, 'epoch': 2.5}\n",
      "{'loss': 0.0979, 'grad_norm': 0.05082309991121292, 'learning_rate': 1.0700000000000001e-05, 'epoch': 2.75}\n",
      "{'loss': 0.1005, 'grad_norm': 0.9843505024909973, 'learning_rate': 1.1700000000000001e-05, 'epoch': 3.0}\n",
      "\n",
      "Epoch 3/10\n",
      "Training Loss: 0.1005\n",
      "Evaluation Loss: 0.7482\n",
      "Evaluation Accuracy: 0.8625\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d26c6830a7f42d58c446e125c050ea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.24778151512145996, 'eval_accuracy': 0.95, 'eval_runtime': 0.2932, 'eval_samples_per_second': 272.814, 'eval_steps_per_second': 34.102, 'epoch': 3.0}\n",
      "{'loss': 0.0036, 'grad_norm': 1.0223650932312012, 'learning_rate': 1.27e-05, 'epoch': 3.25}\n",
      "{'loss': 0.0809, 'grad_norm': 0.7001034021377563, 'learning_rate': 1.3700000000000001e-05, 'epoch': 3.5}\n",
      "{'loss': 0.0011, 'grad_norm': 0.3647365868091583, 'learning_rate': 1.47e-05, 'epoch': 3.75}\n",
      "{'loss': 0.0002, 'grad_norm': 0.048908501863479614, 'learning_rate': 1.5700000000000002e-05, 'epoch': 4.0}\n",
      "\n",
      "Epoch 4/10\n",
      "Training Loss: 0.0002\n",
      "Evaluation Loss: 0.2478\n",
      "Evaluation Accuracy: 0.9500\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1b82e7a4bd34cbe94979bc0e7e3bcb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.31435731053352356, 'eval_accuracy': 0.9625, 'eval_runtime': 0.2874, 'eval_samples_per_second': 278.397, 'eval_steps_per_second': 34.8, 'epoch': 4.0}\n",
      "{'loss': 0.0002, 'grad_norm': 0.009898586198687553, 'learning_rate': 1.6700000000000003e-05, 'epoch': 4.25}\n",
      "{'loss': 0.0002, 'grad_norm': 0.0027319469954818487, 'learning_rate': 1.77e-05, 'epoch': 4.5}\n",
      "{'loss': 0.0001, 'grad_norm': 0.016157740727066994, 'learning_rate': 1.87e-05, 'epoch': 4.75}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0047590662725269794, 'learning_rate': 1.97e-05, 'epoch': 5.0}\n",
      "\n",
      "Epoch 5/10\n",
      "Training Loss: 0.0001\n",
      "Evaluation Loss: 0.3144\n",
      "Evaluation Accuracy: 0.9625\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da39e18227854b919130846f15112df4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.31703728437423706, 'eval_accuracy': 0.9625, 'eval_runtime': 0.276, 'eval_samples_per_second': 289.81, 'eval_steps_per_second': 36.226, 'epoch': 5.0}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0026123346760869026, 'learning_rate': 2.07e-05, 'epoch': 5.25}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0032429040875285864, 'learning_rate': 2.1700000000000002e-05, 'epoch': 5.5}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0021182678174227476, 'learning_rate': 2.2700000000000003e-05, 'epoch': 5.75}\n",
      "{'loss': 0.0001, 'grad_norm': 0.001402911264449358, 'learning_rate': 2.37e-05, 'epoch': 6.0}\n",
      "\n",
      "Epoch 6/10\n",
      "Training Loss: 0.0001\n",
      "Evaluation Loss: 0.3170\n",
      "Evaluation Accuracy: 0.9625\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6b521c805d04543b6ed900c7ee597dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2817559838294983, 'eval_accuracy': 0.9625, 'eval_runtime': 0.2668, 'eval_samples_per_second': 299.889, 'eval_steps_per_second': 37.486, 'epoch': 6.0}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0033579962328076363, 'learning_rate': 2.47e-05, 'epoch': 6.25}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0015444708988070488, 'learning_rate': 2.57e-05, 'epoch': 6.5}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0016248482279479504, 'learning_rate': 2.6700000000000002e-05, 'epoch': 6.75}\n",
      "{'loss': 0.0001, 'grad_norm': 0.008929664269089699, 'learning_rate': 2.7700000000000002e-05, 'epoch': 7.0}\n",
      "\n",
      "Epoch 7/10\n",
      "Training Loss: 0.0001\n",
      "Evaluation Loss: 0.2818\n",
      "Evaluation Accuracy: 0.9625\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c0e14b7f5e446fab3c1396a82b3eccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.28981995582580566, 'eval_accuracy': 0.9625, 'eval_runtime': 0.2716, 'eval_samples_per_second': 294.497, 'eval_steps_per_second': 36.812, 'epoch': 7.0}\n",
      "{'loss': 0.0001, 'grad_norm': 0.002281831344589591, 'learning_rate': 2.87e-05, 'epoch': 7.25}\n",
      "{'loss': 0.0, 'grad_norm': 0.0009053099784068763, 'learning_rate': 2.97e-05, 'epoch': 7.5}\n",
      "{'loss': 0.0, 'grad_norm': 0.001418367144651711, 'learning_rate': 3.07e-05, 'epoch': 7.75}\n",
      "{'loss': 0.0, 'grad_norm': 0.001444044872187078, 'learning_rate': 3.1700000000000005e-05, 'epoch': 8.0}\n",
      "\n",
      "Epoch 8/10\n",
      "Training Loss: 0.0000\n",
      "Evaluation Loss: 0.2898\n",
      "Evaluation Accuracy: 0.9625\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e3810c5422c45c293d8c99c1dfe7057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.282640278339386, 'eval_accuracy': 0.9625, 'eval_runtime': 0.27, 'eval_samples_per_second': 296.325, 'eval_steps_per_second': 37.041, 'epoch': 8.0}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0008772741421125829, 'learning_rate': 3.27e-05, 'epoch': 8.25}\n",
      "{'loss': 0.0, 'grad_norm': 0.0021463658194988966, 'learning_rate': 3.3700000000000006e-05, 'epoch': 8.5}\n",
      "{'loss': 0.0, 'grad_norm': 0.000889813294634223, 'learning_rate': 3.4699999999999996e-05, 'epoch': 8.75}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0031801722943782806, 'learning_rate': 3.57e-05, 'epoch': 9.0}\n",
      "\n",
      "Epoch 9/10\n",
      "Training Loss: 0.0001\n",
      "Evaluation Loss: 0.2826\n",
      "Evaluation Accuracy: 0.9625\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12de6e14ea2a4e5ab113ce1a58da4f3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2961278557777405, 'eval_accuracy': 0.9625, 'eval_runtime': 0.279, 'eval_samples_per_second': 286.782, 'eval_steps_per_second': 35.848, 'epoch': 9.0}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0027870074845850468, 'learning_rate': 3.6700000000000004e-05, 'epoch': 9.25}\n",
      "{'loss': 0.0, 'grad_norm': 0.003563058329746127, 'learning_rate': 3.77e-05, 'epoch': 9.5}\n",
      "{'loss': 0.0, 'grad_norm': 0.0012248293496668339, 'learning_rate': 3.8700000000000006e-05, 'epoch': 9.75}\n",
      "{'loss': 0.0, 'grad_norm': 0.001021943404339254, 'learning_rate': 3.97e-05, 'epoch': 10.0}\n",
      "\n",
      "Epoch 10/10\n",
      "Training Loss: 0.0000\n",
      "Evaluation Loss: 0.2961\n",
      "Evaluation Accuracy: 0.9625\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09461d59f01848dc8b3e780cfca89537",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.31184953451156616, 'eval_accuracy': 0.9625, 'eval_runtime': 0.2711, 'eval_samples_per_second': 295.141, 'eval_steps_per_second': 36.893, 'epoch': 10.0}\n",
      "{'train_runtime': 53.921, 'train_samples_per_second': 59.346, 'train_steps_per_second': 7.418, 'train_loss': 0.2022728704288602, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=400, training_loss=0.2022728704288602, metrics={'train_runtime': 53.921, 'train_samples_per_second': 59.346, 'train_steps_per_second': 7.418, 'total_flos': 841955377152000.0, 'train_loss': 0.2022728704288602, 'epoch': 10.0})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from transformers.trainer_callback import TrainerCallback\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Set seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load the tokenizer and model\n",
    "model_name = \"batterydata/batterybert-cased-abstract\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Assuming raw_datasets is a DatasetDict with \"train\" and \"validation\" splits\n",
    "# and each example has \"text\" and \"labels\" fields\n",
    "\n",
    "# Function to tokenize the datasets\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# Apply tokenization to the datasets\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "\n",
    "# Load the model\n",
    "num_labels = len(set(raw_datasets[\"train\"][\"labels\"]))\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "model = model.to(device)  # Move model to GPU\n",
    "\n",
    "# Load evaluation metric\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "# Create a proper callback by inheriting from TrainerCallback\n",
    "class EpochReportCallback(TrainerCallback):\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "    \n",
    "    def on_epoch_end(self, args, state, control, **kwargs):\n",
    "        self.epoch += 1\n",
    "        \n",
    "        # Get the most recent training loss\n",
    "        if len(state.log_history) > 0:\n",
    "            # Find the most recent training loss entry\n",
    "            train_losses = [log for log in state.log_history if \"loss\" in log and \"eval\" not in log]\n",
    "            if train_losses:\n",
    "                train_loss = train_losses[-1][\"loss\"]\n",
    "                print(f\"\\nEpoch {self.epoch}/{args.num_train_epochs}\")\n",
    "                print(f\"Training Loss: {train_loss:.4f}\")\n",
    "            \n",
    "            # Find the most recent evaluation entries\n",
    "            eval_entries = [log for log in state.log_history if \"eval_loss\" in log]\n",
    "            if eval_entries:\n",
    "                eval_loss = eval_entries[-1][\"eval_loss\"]\n",
    "                eval_accuracy = eval_entries[-1][\"eval_accuracy\"]\n",
    "                print(f\"Evaluation Loss: {eval_loss:.4f}\")\n",
    "                print(f\"Evaluation Accuracy: {eval_accuracy:.4f}\")\n",
    "        \n",
    "        return control\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    # Add CUDA specific arguments\n",
    "    fp16=True,  # Use mixed precision training\n",
    "    no_cuda=False,  # Use CUDA\n",
    "    report_to=\"none\",  # Disable default logging to avoid clutter\n",
    ")\n",
    "\n",
    "# Create the Trainer with an instance of the callback\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EpochReportCallback()],  # Create an instance of the callback class\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print(\"Starting training...\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./batterybert-cased-abstract_finetuned_400_2\\\\tokenizer_config.json',\n",
       " './batterybert-cased-abstract_finetuned_400_2\\\\special_tokens_map.json',\n",
       " './batterybert-cased-abstract_finetuned_400_2\\\\vocab.txt',\n",
       " './batterybert-cased-abstract_finetuned_400_2\\\\added_tokens.json',\n",
       " './batterybert-cased-abstract_finetuned_400_2\\\\tokenizer.json')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the fine-tuned model\n",
    "model.save_pretrained(\"./batterybert-cased-abstract_finetuned_400_2\")\n",
    "tokenizer.save_pretrained(\"./batterybert-cased-abstract_finetuned_400_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For inference\n",
    "def predict(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}  # Move inputs to GPU\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "    return predictions.cpu().numpy()  # Move predictions back to CPU for numpy conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "val_path = r'C:\\Users\\Subways-Sun\\OneDrive\\Documents\\GitHub\\sodium-ion-batteries\\data_annotated\\annotated_data_openai_1.json'\n",
    "with open(val_path, 'r', encoding='utf-8') as f:\n",
    "    val_data = json.load(f)\n",
    "\n",
    "label_bert = []\n",
    "score_bert = []\n",
    "for i in range(len(val_data[\"text\"])):\n",
    "    val_label = predict(val_data[\"text\"][i])\n",
    "    if val_label[0] == 0:\n",
    "        label_bert.append(1)\n",
    "        # score_bert.append(val_label[0][\"score\"])\n",
    "    elif val_label[0] == 1:\n",
    "        label_bert.append(0)\n",
    "        # score_bert.append(val_label[0][\"score\"])\n",
    "\n",
    "val_data[\"label_bert\"] = label_bert\n",
    "val_data[\"score_bert\"] = score_bert\n",
    "print(len(label_bert))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No\tAnno\tOpenAI\tBERT\tBERT Score\n",
      "7\t0\t1\t0\n",
      "21\t0\t1\t0\n",
      "34\t0\t1\t0\n",
      "36\t0\t1\t0\n",
      "53\t0\t1\t0\n",
      "72\t1\t1\t0\n",
      "79\t0\t1\t0\n",
      "80\t0\t1\t0\n",
      "83\t0\t0\t1\n",
      "99\t0\t1\t0\n",
      "OpenAI False Positive: 8\n",
      "OpenAI False Negative: 0\n",
      "Bert False Positive: 1\n",
      "Bert False Negative: 1\n"
     ]
    }
   ],
   "source": [
    "label_openai = val_data[\"label_openai\"]\n",
    "label_annotated = val_data[\"label_annotated\"]\n",
    "print(f\"No\\tAnno\\tOpenAI\\tBERT\\tBERT Score\")\n",
    "\n",
    "openai_fp = 0\n",
    "openai_fn = 0\n",
    "bert_fp = 0\n",
    "bert_fn = 0\n",
    "\n",
    "for i in range(len(label_bert)):\n",
    "    if (label_bert[i] + label_openai[i] + label_annotated[i] != 3) and (label_bert[i] + label_openai[i] + label_annotated[i] != 0):\n",
    "        print(f\"{i}\\t{label_annotated[i]}\\t{label_openai[i]}\\t{label_bert[i]}\")\n",
    "        if label_bert[i] == 1 and label_annotated[i] == 0:\n",
    "            bert_fp += 1\n",
    "        elif label_bert[i] == 0 and label_annotated[i] == 1:\n",
    "            bert_fn += 1\n",
    "        if label_openai[i] == 1 and label_annotated[i] == 0:\n",
    "            openai_fp += 1\n",
    "        elif label_openai[i] == 0 and label_annotated[i] == 1:\n",
    "            openai_fn += 1\n",
    "\n",
    "print(f\"OpenAI False Positive: {openai_fp}\")\n",
    "print(f\"OpenAI False Negative: {openai_fn}\")\n",
    "print(f\"Bert False Positive: {bert_fp}\")\n",
    "print(f\"Bert False Negative: {bert_fn}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
