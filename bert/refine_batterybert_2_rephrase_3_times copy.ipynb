{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# Load data\n",
    "data_path = r'C:\\Users\\Subways-Sun\\OneDrive\\Documents\\GitHub\\sodium-ion-batteries\\data_annotated\\search_20241106-223705_sodium+ion+battery+anode-sodium+ion+battery+cathode-sodium+ion+battery+electrode_annotated_rephrased.json'\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Prepare data\n",
    "texts = []\n",
    "labels_raw = []\n",
    "for i in data:\n",
    "    texts.append(i[\"text\"])\n",
    "    labels_raw.append(i[\"label_int\"])\n",
    "\n",
    "labels = []\n",
    "for i in labels_raw:\n",
    "    if i == 0:\n",
    "        labels.append(1)\n",
    "    elif i == 1:\n",
    "        labels.append(0)\n",
    "\n",
    "# Split data\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    texts,\n",
    "    labels,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = Dataset.from_dict({\n",
    "    'text': train_texts,\n",
    "    'labels': train_labels\n",
    "})\n",
    "val_dataset = Dataset.from_dict({\n",
    "    'text': val_texts,\n",
    "    'labels': val_labels\n",
    "})\n",
    "raw_datasets = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': val_dataset\n",
    "})\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'labels'],\n",
      "        num_rows: 320\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'labels'],\n",
      "        num_rows: 80\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(raw_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80eeb4f6532f4daab49cdfc3892125d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/320 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a00c390a4c7431381b23eb223941e65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/80 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'EpochReportCallback' object has no attribute 'on_init_end'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 84\u001b[0m\n\u001b[0;32m     65\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[0;32m     66\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./results\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     67\u001b[0m     num_train_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     80\u001b[0m     report_to\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# Disable default logging to avoid clutter\u001b[39;00m\n\u001b[0;32m     81\u001b[0m )\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# Create the Trainer with an instance of the callback\u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenized_datasets\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenized_datasets\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalidation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mEpochReportCallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Create an instance of the callback class\u001b[39;49;00m\n\u001b[0;32m     91\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting training...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\utils\\deprecation.py:165\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS):\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\trainer.py:736\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[1;34m(self, model, args, data_collator, train_dataset, eval_dataset, processing_class, model_init, compute_loss_func, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_names \u001b[38;5;241m=\u001b[39m default_label_names \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mlabel_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mlabel_names\n\u001b[0;32m    735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcan_return_loss \u001b[38;5;241m=\u001b[39m can_return_loss(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m--> 736\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallback_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_init_end\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontrol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    738\u001b[0m \u001b[38;5;66;03m# Internal variables to help with automatic batch size reduction\u001b[39;00m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mtrain_batch_size\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\trainer_callback.py:464\u001b[0m, in \u001b[0;36mCallbackHandler.on_init_end\u001b[1;34m(self, args, state, control)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_init_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: TrainingArguments, state: TrainerState, control: TrainerControl):\n\u001b[1;32m--> 464\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_event\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mon_init_end\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrol\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\trainer_callback.py:518\u001b[0m, in \u001b[0;36mCallbackHandler.call_event\u001b[1;34m(self, event, args, state, control, **kwargs)\u001b[0m\n\u001b[0;32m    516\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_event\u001b[39m(\u001b[38;5;28mself\u001b[39m, event, args, state, control, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    517\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[1;32m--> 518\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m)\u001b[49m(\n\u001b[0;32m    519\u001b[0m             args,\n\u001b[0;32m    520\u001b[0m             state,\n\u001b[0;32m    521\u001b[0m             control,\n\u001b[0;32m    522\u001b[0m             model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[0;32m    523\u001b[0m             processing_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessing_class,\n\u001b[0;32m    524\u001b[0m             optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer,\n\u001b[0;32m    525\u001b[0m             lr_scheduler\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_scheduler,\n\u001b[0;32m    526\u001b[0m             train_dataloader\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_dataloader,\n\u001b[0;32m    527\u001b[0m             eval_dataloader\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_dataloader,\n\u001b[0;32m    528\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    529\u001b[0m         )\n\u001b[0;32m    530\u001b[0m         \u001b[38;5;66;03m# A Callback can skip the return of `control` if it doesn't change it.\u001b[39;00m\n\u001b[0;32m    531\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'EpochReportCallback' object has no attribute 'on_init_end'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Set seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load the tokenizer and model\n",
    "model_name = \"batterydata/batterybert-cased-abstract\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Assuming raw_datasets is a DatasetDict with \"train\" and \"validation\" splits\n",
    "# and each example has \"text\" and \"labels\" fields\n",
    "\n",
    "# Function to tokenize the datasets\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# Apply tokenization to the datasets\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "\n",
    "# Load the model\n",
    "num_labels = len(set(raw_datasets[\"train\"][\"labels\"]))\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "model = model.to(device)  # Move model to GPU\n",
    "\n",
    "# Load evaluation metric\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "# Create a callback to report metrics after each epoch\n",
    "class EpochReportCallback:\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "    \n",
    "    def on_epoch_end(self, args, state, control, **kwargs):\n",
    "        self.epoch += 1\n",
    "        \n",
    "        # Get the current train loss\n",
    "        train_loss = state.log_history[-2][\"loss\"] if len(state.log_history) >= 2 else 0\n",
    "        print(f\"\\nEpoch {self.epoch}/10\")\n",
    "        print(f\"Training Loss: {train_loss:.4f}\")\n",
    "        \n",
    "        # Since we're using evaluation_strategy=\"epoch\", evaluation metrics should be in log_history\n",
    "        if len(state.log_history) >= 1 and \"eval_loss\" in state.log_history[-1]:\n",
    "            eval_loss = state.log_history[-1][\"eval_loss\"]\n",
    "            eval_accuracy = state.log_history[-1][\"eval_accuracy\"]\n",
    "            \n",
    "            print(f\"Evaluation Loss: {eval_loss:.4f}\")\n",
    "            print(f\"Evaluation Accuracy: {eval_accuracy:.4f}\")\n",
    "        \n",
    "        return control\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    # Add CUDA specific arguments\n",
    "    fp16=True,  # Use mixed precision training\n",
    "    no_cuda=False,  # Use CUDA\n",
    "    report_to=\"none\",  # Disable default logging to avoid clutter\n",
    ")\n",
    "\n",
    "# Create the Trainer with an instance of the callback\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EpochReportCallback()],  # Create an instance of the callback class\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print(\"Starting training...\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the fine-tuned model\n",
    "model.save_pretrained(\"./batterybert-cased-abstract_finetuned_400_2\")\n",
    "tokenizer.save_pretrained(\"./batterybert-cased-abstract_finetuned_400_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For inference\n",
    "def predict(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}  # Move inputs to GPU\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "    return predictions.cpu().numpy()  # Move predictions back to CPU for numpy conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    }
   ],
   "source": [
    "val_path = r'C:\\Users\\Subways-Sun\\OneDrive\\Documents\\GitHub\\sodium-ion-batteries\\data_annotated\\annotated_data_openai_1.json'\n",
    "with open(val_path, 'r', encoding='utf-8') as f:\n",
    "    val_data = json.load(f)\n",
    "\n",
    "label_bert = []\n",
    "score_bert = []\n",
    "for i in range(len(val_data[\"text\"])):\n",
    "    val_label = predict(val_data[\"text\"][i])\n",
    "    if val_label[0][\"label\"] == \"battery\":\n",
    "        label_bert.append(1)\n",
    "        score_bert.append(val_label[0][\"score\"])\n",
    "    elif val_label[0][\"label\"] == \"non-battery\":\n",
    "        label_bert.append(0)\n",
    "        score_bert.append(val_label[0][\"score\"])\n",
    "\n",
    "val_data[\"label_bert\"] = label_bert\n",
    "val_data[\"score_bert\"] = score_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No\tAnno\tOpenAI\tBERT\tBERT Score\n",
      "7\t0\t1\t0\t0.9998679161071777\n",
      "14\t0\t0\t1\t0.9926759600639343\n",
      "21\t0\t1\t0\t0.9998675584793091\n",
      "26\t1\t1\t0\t0.9979070425033569\n",
      "27\t1\t1\t0\t0.9998754262924194\n",
      "34\t0\t1\t0\t0.9998750686645508\n",
      "36\t0\t1\t0\t0.9998751878738403\n",
      "39\t1\t1\t0\t0.9998252987861633\n",
      "42\t1\t1\t0\t0.960843563079834\n",
      "45\t1\t1\t0\t0.9922792911529541\n",
      "47\t1\t1\t0\t0.999674916267395\n",
      "53\t0\t1\t0\t0.9998691082000732\n",
      "75\t0\t0\t1\t0.993808925151825\n",
      "79\t0\t1\t0\t0.9998757839202881\n",
      "80\t0\t1\t0\t0.9997312426567078\n",
      "83\t0\t0\t1\t0.9937708973884583\n",
      "86\t1\t1\t0\t0.9607234597206116\n",
      "87\t1\t1\t0\t0.9994949102401733\n",
      "89\t1\t1\t0\t0.9998729228973389\n",
      "99\t0\t1\t0\t0.9998770952224731\n",
      "OpenAI False Positive: 8\n",
      "OpenAI False Negative: 0\n",
      "Bert False Positive: 3\n",
      "Bert False Negative: 9\n"
     ]
    }
   ],
   "source": [
    "label_openai = val_data[\"label_openai\"]\n",
    "label_annotated = val_data[\"label_annotated\"]\n",
    "print(f\"No\\tAnno\\tOpenAI\\tBERT\\tBERT Score\")\n",
    "\n",
    "openai_fp = 0\n",
    "openai_fn = 0\n",
    "bert_fp = 0\n",
    "bert_fn = 0\n",
    "\n",
    "for i in range(len(label_bert)):\n",
    "    if (label_bert[i] + label_openai[i] + label_annotated[i] != 3) and (label_bert[i] + label_openai[i] + label_annotated[i] != 0):\n",
    "        print(f\"{i}\\t{label_annotated[i]}\\t{label_openai[i]}\\t{label_bert[i]}\\t{score_bert[i]}\")\n",
    "        if label_bert[i] == 1 and label_annotated[i] == 0:\n",
    "            bert_fp += 1\n",
    "        elif label_bert[i] == 0 and label_annotated[i] == 1:\n",
    "            bert_fn += 1\n",
    "        if label_openai[i] == 1 and label_annotated[i] == 0:\n",
    "            openai_fp += 1\n",
    "        elif label_openai[i] == 0 and label_annotated[i] == 1:\n",
    "            openai_fn += 1\n",
    "\n",
    "print(f\"OpenAI False Positive: {openai_fp}\")\n",
    "print(f\"OpenAI False Negative: {openai_fn}\")\n",
    "print(f\"Bert False Positive: {bert_fp}\")\n",
    "print(f\"Bert False Negative: {bert_fn}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
