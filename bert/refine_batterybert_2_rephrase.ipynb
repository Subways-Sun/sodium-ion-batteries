{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "data_path = r'C:\\Users\\Subways-Sun\\OneDrive\\Documents\\GitHub\\sodium-ion-batteries\\data_annotated\\search_20241106-223705_sodium+ion+battery+anode-sodium+ion+battery+cathode-sodium+ion+battery+electrode_annotated_rephrased_once.json'\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "texts = []\n",
    "labels_raw = []\n",
    "\n",
    "for i in data:\n",
    "    texts.append(i[\"text\"])\n",
    "    labels_raw.append(i[\"label_int\"])\n",
    "\n",
    "labels = []\n",
    "for i in labels_raw:\n",
    "    if i == 0:\n",
    "        labels.append(1)\n",
    "    elif i == 1:\n",
    "        labels.append(0)\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    texts,\n",
    "    labels,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_dataset = Dataset.from_dict({\n",
    "    'text': train_texts,\n",
    "    'labels': train_labels\n",
    "})\n",
    "\n",
    "val_dataset = Dataset.from_dict({\n",
    "    'text': val_texts,\n",
    "    'labels': val_labels\n",
    "})\n",
    "\n",
    "raw_datasets = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': val_dataset\n",
    "})\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'labels'],\n",
      "        num_rows: 160\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'labels'],\n",
      "        num_rows: 40\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(raw_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e73e2921b789484cb7852b32d0c6fcdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/160 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e4a2a8b0bfa493cbd848b4138f63299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"batterydata/batterybert-cased-abstract\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2, torch_dtype=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\",\n",
    "                                  eval_strategy=\"epoch\",\n",
    "                                  num_train_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f09f016025984218ab8f88d3dd4b81cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "579b7aa5aa1c46749b6777312933f0d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5123046636581421, 'eval_accuracy': 0.875, 'eval_runtime': 0.8318, 'eval_samples_per_second': 48.09, 'eval_steps_per_second': 6.011, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "599c79ad4764409eabdbf7e9326ff440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.33328187465667725, 'eval_accuracy': 0.9, 'eval_runtime': 0.8785, 'eval_samples_per_second': 45.535, 'eval_steps_per_second': 5.692, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75b5b975427a4630a0cee3c4308a9415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.48736315965652466, 'eval_accuracy': 0.875, 'eval_runtime': 0.8561, 'eval_samples_per_second': 46.726, 'eval_steps_per_second': 5.841, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c00441ab271348d2b788bd7c9c387a42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.24066007137298584, 'eval_accuracy': 0.95, 'eval_runtime': 0.8517, 'eval_samples_per_second': 46.963, 'eval_steps_per_second': 5.87, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a16453a8178040d5afdc91da61a92f34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11825376749038696, 'eval_accuracy': 0.95, 'eval_runtime': 0.7716, 'eval_samples_per_second': 51.838, 'eval_steps_per_second': 6.48, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5761389795f4e74976bce3182223fd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0028533772565424442, 'eval_accuracy': 1.0, 'eval_runtime': 0.763, 'eval_samples_per_second': 52.425, 'eval_steps_per_second': 6.553, 'epoch': 6.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "295ae2026b764a6a984f4355a7f097d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0006424685707315803, 'eval_accuracy': 1.0, 'eval_runtime': 0.761, 'eval_samples_per_second': 52.563, 'eval_steps_per_second': 6.57, 'epoch': 7.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b0d9bda7488418da97dbaa5cc69e087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.036356765776872635, 'eval_accuracy': 0.975, 'eval_runtime': 0.8041, 'eval_samples_per_second': 49.743, 'eval_steps_per_second': 6.218, 'epoch': 8.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cd683810bb246e492b98cba2f6e65b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.05163665488362312, 'eval_accuracy': 0.975, 'eval_runtime': 0.7632, 'eval_samples_per_second': 52.409, 'eval_steps_per_second': 6.551, 'epoch': 9.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25409d9fb23f423aaaeb086c2ea7b593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0006281362730078399, 'eval_accuracy': 1.0, 'eval_runtime': 0.6714, 'eval_samples_per_second': 59.578, 'eval_steps_per_second': 7.447, 'epoch': 10.0}\n",
      "{'train_runtime': 633.5906, 'train_samples_per_second': 2.525, 'train_steps_per_second': 0.316, 'train_loss': 0.18963598251342773, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=200, training_loss=0.18963598251342773, metrics={'train_runtime': 633.5906, 'train_samples_per_second': 2.525, 'train_steps_per_second': 0.316, 'total_flos': 420977688576000.0, 'train_loss': 0.18963598251342773, 'epoch': 10.0})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc92cf34a2104876b4280cc613c07122",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.0006281362730078399,\n",
       " 'eval_accuracy': 1.0,\n",
       " 'eval_runtime': 0.6836,\n",
       " 'eval_samples_per_second': 58.516,\n",
       " 'eval_steps_per_second': 7.315,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "SafetensorError",
     "evalue": "Error while serializing: IoError(Os { code: 1224, kind: Uncategorized, message: \"The requested operation cannot be performed on a file with a user-mapped section open.\" })",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSafetensorError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatterybert-cased-abstract_finetuned_200\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\trainer.py:3730\u001b[0m, in \u001b[0;36mTrainer.save_model\u001b[1;34m(self, output_dir, _internal_call)\u001b[0m\n\u001b[0;32m   3727\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped\u001b[38;5;241m.\u001b[39msave_checkpoint(output_dir)\n\u001b[0;32m   3729\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[1;32m-> 3730\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3732\u001b[0m \u001b[38;5;66;03m# Push to the Hub when `save_model` is called by the user.\u001b[39;00m\n\u001b[0;32m   3733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpush_to_hub \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _internal_call:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\trainer.py:3834\u001b[0m, in \u001b[0;36mTrainer._save\u001b[1;34m(self, output_dir, state_dict)\u001b[0m\n\u001b[0;32m   3832\u001b[0m             torch\u001b[38;5;241m.\u001b[39msave(state_dict, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, WEIGHTS_NAME))\n\u001b[0;32m   3833\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3834\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3835\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_serialization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_safetensors\u001b[49m\n\u001b[0;32m   3836\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessing_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3839\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessing_class\u001b[38;5;241m.\u001b[39msave_pretrained(output_dir)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\modeling_utils.py:3029\u001b[0m, in \u001b[0;36mPreTrainedModel.save_pretrained\u001b[1;34m(self, save_directory, is_main_process, state_dict, save_function, push_to_hub, max_shard_size, safe_serialization, variant, token, save_peft_format, **kwargs)\u001b[0m\n\u001b[0;32m   3024\u001b[0m     gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[0;32m   3026\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m safe_serialization:\n\u001b[0;32m   3027\u001b[0m     \u001b[38;5;66;03m# At some point we will need to deal better with save_function (used for TPU and other distributed\u001b[39;00m\n\u001b[0;32m   3028\u001b[0m     \u001b[38;5;66;03m# joyfulness), but for now this enough.\u001b[39;00m\n\u001b[1;32m-> 3029\u001b[0m     \u001b[43msafe_save_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshard\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshard_file\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mformat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3030\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3031\u001b[0m     save_function(shard, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_directory, shard_file))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\safetensors\\torch.py:286\u001b[0m, in \u001b[0;36msave_file\u001b[1;34m(tensors, filename, metadata)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_file\u001b[39m(\n\u001b[0;32m    256\u001b[0m     tensors: Dict[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor],\n\u001b[0;32m    257\u001b[0m     filename: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike],\n\u001b[0;32m    258\u001b[0m     metadata: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    259\u001b[0m ):\n\u001b[0;32m    260\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;124;03m    Saves a dictionary of tensors into raw bytes in safetensors format.\u001b[39;00m\n\u001b[0;32m    262\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 286\u001b[0m     \u001b[43mserialize_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_flatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mSafetensorError\u001b[0m: Error while serializing: IoError(Os { code: 1224, kind: Uncategorized, message: \"The requested operation cannot be performed on a file with a user-mapped section open.\" })"
     ]
    }
   ],
   "source": [
    "trainer.save_model(\"batterybert-cased-abstract_finetuned_200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"text-classification\", model=\"batterybert-cased-abstract_finetuned_200\", tokenizer=tokenizer, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = r\"MXene nanosheets and ordered porous carbons both have their own advantages and disadvantages. Assembling and combining the advantages of the two will be a good choice for battery electrode hosts of active materials. In this work, an electrostatic separation-adsorption strategy is proposed to realize the ordered alternating self-assembly of MXene nanosheets and ordered porous carbon (MPOC), obtaining a unique wall-like porous material with a high conductivity and interconnected porous nanostructure, which strengthens the transfer rate of electrons and ions simultaneously. Meanwhile, the introduction of N-doping from porous carbon into MPOC prolongs the cycle life. When use red phosphorus (RP) as active materials, the MPOC@RP anode exhibited high-capacity output (2454.3 and 2408.1 mAh g-1 in lithium-ion batteries (LIBs) and sodium-ion batteries (SIBs) at 0.1 C) and long cycle life (the decay rates per cycle of 0.028% and 0.036% after 1500 and 1200 cycles at 2 C in LIBs and SIBs respectively). The successful application in RP anodes displays great potential in other electrode materials such as silicon, sulfur, selenium, and so on. Meanwhile, this strategy is also effective to design other composites materials like MXene and carbon nanotubes, MXene and Graphene, and so on.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_out = AutoModelForSequenceClassification.from_pretrained(\"batterybert-cased-abstract_finetuned_200\")\n",
    "# with torch.no_grad():\n",
    "#     logits = model_out(text).logits\n",
    "# predicted_class_id = logits.argmax().item()\n",
    "# print(predicted_class_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'battery', 'score': 0.999872088432312}]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(r\"MXene nanosheets and ordered porous carbons both have their own advantages and disadvantages. Assembling and combining the advantages of the two will be a good choice for battery electrode hosts of active materials. In this work, an electrostatic separation-adsorption strategy is proposed to realize the ordered alternating self-assembly of MXene nanosheets and ordered porous carbon (MPOC), obtaining a unique wall-like porous material with a high conductivity and interconnected porous nanostructure, which strengthens the transfer rate of electrons and ions simultaneously. Meanwhile, the introduction of N-doping from porous carbon into MPOC prolongs the cycle life. When use red phosphorus (RP) as active materials, the MPOC@RP anode exhibited high-capacity output (2454.3 and 2408.1 mAh g-1 in lithium-ion batteries (LIBs) and sodium-ion batteries (SIBs) at 0.1 C) and long cycle life (the decay rates per cycle of 0.028% and 0.036% after 1500 and 1200 cycles at 2 C in LIBs and SIBs respectively). The successful application in RP anodes displays great potential in other electrode materials such as silicon, sulfur, selenium, and so on. Meanwhile, this strategy is also effective to design other composites materials like MXene and carbon nanotubes, MXene and Graphene, and so on.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'battery'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(r\"Highly crystalline CuFeS2 containing earth-abundant and environmentally friendly elements prepared via a high-temperature synthesis exhibits an excellent electrochemical performance as an anode material in sodium-ion batteries. The initial specific capacity of 460 mAh g-1 increases to 512 mAh g-1 in the 150th cycle and then decreases to a still very high value of 444 mAh g-1 at 0.5 A g-1 in the remaining 550 cycles. Even for a large current density, a pronounced cycling stability is observed. Here, we demonstrate that combining the results of X-ray powder diffraction experiments, pair distribution function analysis, and 23Na NMR and MÃ¶ssbauer spectroscopy investigations performed at different stages of discharging and charging processes allows elucidation of very complex reaction mechanisms. In the first step after uptake of 1 Na/CuFeS2, nanocrystalline NaCuFeS2 is formed as an intermediate phase, which surprisingly could be recovered during charging. On increasing the Na content, Cu+ is reduced to nanocrystalline Cu, while nanocrystalline Na2S and nanosized elemental Fe are formed in the discharged state. After charging, the main crystalline phase is NaCuFeS2. At the 150th cycle, the mechanisms clearly changed, and in the charged state, nanocrystalline CuxS phases are observed. At later stages of cycling, the mechanisms are altered again: NaF, Cu2S, and Cu7.2S4 appeared in the discharged state, while NaF and Cu5FeS4 are observed in the charged state. In contrast to a typical conversion reaction, nanocrystalline phases play the dominant role, which are responsible for the high reversible capacity and long-term stability.\")[0][\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_path = r'C:\\Users\\Subways-Sun\\OneDrive\\Documents\\GitHub\\sodium-ion-batteries\\data_annotated\\annotated_data_openai.json'\n",
    "with open(val_path, 'r', encoding='utf-8') as f:\n",
    "    val_data = json.load(f)\n",
    "\n",
    "label_bert = []\n",
    "score_bert = []\n",
    "for i in range(len(val_data[\"text\"])):\n",
    "    val_label = classifier(val_data[\"text\"][i][:512])\n",
    "    if val_label[0][\"label\"] == \"battery\":\n",
    "        label_bert.append(1)\n",
    "        score_bert.append(val_label[0][\"score\"])\n",
    "    elif val_label[0][\"label\"] == \"non-battery\":\n",
    "        label_bert.append(0)\n",
    "        score_bert.append(val_label[0][\"score\"])\n",
    "\n",
    "val_data[\"label_bert\"] = label_bert\n",
    "val_data[\"score_bert\"] = score_bert\n",
    "\n",
    "# result_path = r'C:\\Users\\Subways-Sun\\OneDrive\\Documents\\GitHub\\sodium-ion-batteries\\data_annotated\\annotated_data_openai_bert.json'\n",
    "# with open(result_path, 'w', encoding='utf-8') as f:\n",
    "#     json.dump(val_data, f, indent=4, ensure_ascii=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No\tAnno\tOpenAI\tBERT\tBERT Score\n",
      "4\t0\t1\t1\t0.9994474053382874\n",
      "5\t0\t1\t0\t0.9999542236328125\n",
      "8\t1\t0\t1\t0.9998757839202881\n",
      "9\t0\t0\t1\t0.9998512268066406\n",
      "11\t1\t1\t0\t0.9999184608459473\n",
      "13\t1\t1\t0\t0.9579297304153442\n",
      "14\t0\t0\t1\t0.9998705387115479\n",
      "17\t0\t0\t1\t0.9998308420181274\n",
      "20\t0\t0\t1\t0.999725878238678\n",
      "25\t0\t0\t1\t0.999792754650116\n",
      "27\t0\t0\t1\t0.9985211491584778\n",
      "29\t1\t1\t0\t0.9984087347984314\n",
      "35\t1\t1\t0\t0.9995049238204956\n",
      "36\t0\t0\t1\t0.9998750686645508\n",
      "41\t1\t1\t0\t0.8142088651657104\n",
      "43\t1\t1\t0\t0.999729573726654\n",
      "44\t0\t0\t1\t0.9998645782470703\n",
      "45\t1\t1\t0\t0.9997357726097107\n",
      "49\t1\t0\t0\t0.9997065663337708\n",
      "51\t1\t1\t0\t0.9910997748374939\n",
      "52\t0\t0\t1\t0.978841245174408\n",
      "53\t0\t0\t1\t0.9998689889907837\n",
      "58\t0\t0\t1\t0.9998679161071777\n",
      "60\t0\t0\t1\t0.99915611743927\n",
      "63\t0\t1\t0\t0.999935507774353\n",
      "66\t0\t0\t1\t0.9998705387115479\n",
      "68\t1\t0\t1\t0.9986616373062134\n",
      "80\t0\t1\t0\t0.9999425411224365\n",
      "88\t0\t0\t1\t0.9998756647109985\n",
      "94\t0\t0\t1\t0.9998705387115479\n",
      "95\t0\t1\t0\t0.9999485015869141\n",
      "97\t0\t0\t1\t0.9993574023246765\n",
      "99\t0\t0\t1\t0.9959127306938171\n",
      "101\t0\t0\t1\t0.999870777130127\n",
      "103\t0\t1\t0\t0.9999450445175171\n",
      "108\t0\t0\t1\t0.9998674392700195\n",
      "112\t0\t1\t1\t0.9997765421867371\n",
      "120\t0\t0\t1\t0.9998621940612793\n",
      "121\t0\t0\t1\t0.9996837377548218\n",
      "134\t0\t0\t1\t0.7006495594978333\n",
      "135\t0\t1\t0\t0.9999451637268066\n",
      "136\t0\t1\t1\t0.999874472618103\n",
      "137\t0\t1\t0\t0.9999384880065918\n",
      "139\t1\t1\t0\t0.9997223019599915\n",
      "143\t0\t0\t1\t0.9996598958969116\n",
      "OpenAI True Positive: 83\n",
      "OpenAI True Negative: 54\n",
      "OpenAI False Positive: 10\n",
      "OpenAI False Negative: 3\n",
      "Bert True Positive: 76\n",
      "Bert True Negative: 38\n",
      "Bert False Positive: 26\n",
      "Bert False Negative: 10\n"
     ]
    }
   ],
   "source": [
    "label_openai = val_data[\"label_openai\"]\n",
    "label_annotated = val_data[\"label_annotated\"]\n",
    "print(f\"No\\tAnno\\tOpenAI\\tBERT\\tBERT Score\")\n",
    "\n",
    "openai_tp = 0\n",
    "openai_tn = 0\n",
    "openai_fp = 0\n",
    "openai_fn = 0\n",
    "bert_tp = 0\n",
    "bert_tn = 0\n",
    "bert_fp = 0\n",
    "bert_fn = 0\n",
    "\n",
    "for i in range(len(label_bert)):\n",
    "    if (label_bert[i] + label_openai[i] + label_annotated[i] != 3) and (label_bert[i] + label_openai[i] + label_annotated[i] != 0):\n",
    "        print(f\"{i}\\t{label_annotated[i]}\\t{label_openai[i]}\\t{label_bert[i]}\\t{score_bert[i]}\")\n",
    "        if label_bert[i] == 1 and label_annotated[i] == 0:\n",
    "            bert_fp += 1\n",
    "        elif label_bert[i] == 0 and label_annotated[i] == 1:\n",
    "            bert_fn += 1\n",
    "        if label_openai[i] == 1 and label_annotated[i] == 0:\n",
    "            openai_fp += 1\n",
    "        elif label_openai[i] == 0 and label_annotated[i] == 1:\n",
    "            openai_fn += 1\n",
    "    if label_bert[i] == 1 and label_annotated[i] == 1:\n",
    "        bert_tp += 1\n",
    "    if label_bert[i] == 0 and label_annotated[i] == 0:\n",
    "        bert_tn += 1\n",
    "    if label_openai[i] == 1 and label_annotated[i] == 1:\n",
    "        openai_tp += 1\n",
    "    if label_openai[i] == 0 and label_annotated[i] == 0:\n",
    "        openai_tn += 1\n",
    "        \n",
    "print(f\"OpenAI True Positive: {openai_tp}\")\n",
    "print(f\"OpenAI True Negative: {openai_tn}\")\n",
    "print(f\"OpenAI False Positive: {openai_fp}\")\n",
    "print(f\"OpenAI False Negative: {openai_fn}\")\n",
    "print(f\"Bert True Positive: {bert_tp}\")\n",
    "print(f\"Bert True Negative: {bert_tn}\")\n",
    "print(f\"Bert False Positive: {bert_fp}\")\n",
    "print(f\"Bert False Negative: {bert_fn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_path = r'C:\\Users\\Subways-Sun\\OneDrive\\Documents\\GitHub\\sodium-ion-batteries\\data_annotated\\annotated_data_openai_1.json'\n",
    "with open(val_path, 'r', encoding='utf-8') as f:\n",
    "    val_data = json.load(f)\n",
    "\n",
    "label_bert = []\n",
    "score_bert = []\n",
    "for i in range(len(val_data[\"text\"])):\n",
    "    val_label = classifier(val_data[\"text\"][i][:512])\n",
    "    if val_label[0][\"label\"] == \"battery\":\n",
    "        label_bert.append(1)\n",
    "        score_bert.append(val_label[0][\"score\"])\n",
    "    elif val_label[0][\"label\"] == \"non-battery\":\n",
    "        label_bert.append(0)\n",
    "        score_bert.append(val_label[0][\"score\"])\n",
    "\n",
    "val_data[\"label_bert\"] = label_bert\n",
    "val_data[\"score_bert\"] = score_bert\n",
    "\n",
    "# result_path = r'C:\\Users\\Subways-Sun\\OneDrive\\Documents\\GitHub\\sodium-ion-batteries\\data_annotated\\annotated_data_openai_bert.json'\n",
    "# with open(result_path, 'w', encoding='utf-8') as f:\n",
    "#     json.dump(val_data, f, indent=4, ensure_ascii=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No\tAnno\tOpenAI\tBERT\tBERT Score\n",
      "7\t0\t1\t0\t0.9999476671218872\n",
      "11\t0\t1\t0\t0.9999425411224365\n",
      "21\t0\t1\t0\t0.9999438524246216\n",
      "27\t1\t1\t0\t0.9984087347984314\n",
      "34\t0\t1\t0\t0.9999485015869141\n",
      "36\t0\t1\t0\t0.9999450445175171\n",
      "39\t1\t1\t0\t0.9997223019599915\n",
      "47\t1\t1\t0\t0.9910997748374939\n",
      "53\t0\t1\t0\t0.999935507774353\n",
      "54\t1\t1\t0\t0.999729573726654\n",
      "57\t1\t1\t0\t0.8142088651657104\n",
      "72\t1\t1\t0\t0.9997357726097107\n",
      "73\t1\t1\t0\t0.9995049238204956\n",
      "75\t1\t0\t0\t0.9997065663337708\n",
      "79\t0\t1\t0\t0.9999542236328125\n",
      "80\t0\t1\t0\t0.9999384880065918\n",
      "83\t0\t0\t1\t0.999870777130127\n",
      "86\t1\t1\t0\t0.9579297304153442\n",
      "88\t0\t1\t0\t0.9999287128448486\n",
      "89\t1\t1\t0\t0.9999184608459473\n",
      "99\t0\t1\t0\t0.9999451637268066\n",
      "OpenAI False Positive: 10\n",
      "OpenAI False Negative: 1\n",
      "Bert False Positive: 1\n",
      "Bert False Negative: 10\n"
     ]
    }
   ],
   "source": [
    "label_openai = val_data[\"label_openai\"]\n",
    "label_annotated = val_data[\"label_annotated\"]\n",
    "print(f\"No\\tAnno\\tOpenAI\\tBERT\\tBERT Score\")\n",
    "\n",
    "openai_fp = 0\n",
    "openai_fn = 0\n",
    "bert_fp = 0\n",
    "bert_fn = 0\n",
    "\n",
    "for i in range(len(label_bert)):\n",
    "    if (label_bert[i] + label_openai[i] + label_annotated[i] != 3) and (label_bert[i] + label_openai[i] + label_annotated[i] != 0):\n",
    "        print(f\"{i}\\t{label_annotated[i]}\\t{label_openai[i]}\\t{label_bert[i]}\\t{score_bert[i]}\")\n",
    "        if label_bert[i] == 1 and label_annotated[i] == 0:\n",
    "            bert_fp += 1\n",
    "        elif label_bert[i] == 0 and label_annotated[i] == 1:\n",
    "            bert_fn += 1\n",
    "        if label_openai[i] == 1 and label_annotated[i] == 0:\n",
    "            openai_fp += 1\n",
    "        elif label_openai[i] == 0 and label_annotated[i] == 1:\n",
    "            openai_fn += 1\n",
    "\n",
    "print(f\"OpenAI False Positive: {openai_fp}\")\n",
    "print(f\"OpenAI False Negative: {openai_fn}\")\n",
    "print(f\"Bert False Positive: {bert_fp}\")\n",
    "print(f\"Bert False Negative: {bert_fn}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
