{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "data_path = r'C:\\Users\\Subways-Sun\\OneDrive\\Documents\\GitHub\\sodium-ion-batteries\\data_annotated\\search_20241106-223705_sodium+ion+battery+anode-sodium+ion+battery+cathode-sodium+ion+battery+electrode_annotated_50irrelevant_rephrased3.json'\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "texts = []\n",
    "labels_raw = []\n",
    "\n",
    "for i in data:\n",
    "    texts.append(i[\"text\"])\n",
    "    labels_raw.append(i[\"label_int\"])\n",
    "\n",
    "labels = []\n",
    "for i in labels_raw:\n",
    "    if i == 0:\n",
    "        labels.append(1)\n",
    "    elif i == 1:\n",
    "        labels.append(0)\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    texts,\n",
    "    labels,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_dataset = Dataset.from_dict({\n",
    "    'text': train_texts,\n",
    "    'labels': train_labels\n",
    "})\n",
    "\n",
    "val_dataset = Dataset.from_dict({\n",
    "    'text': val_texts,\n",
    "    'labels': val_labels\n",
    "})\n",
    "\n",
    "raw_datasets = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': val_dataset\n",
    "})\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'labels'],\n",
      "        num_rows: 480\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'labels'],\n",
      "        num_rows: 120\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(raw_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f4db0c7cd2249feb1c02db7b4cff7cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b4f51cb31b440eb8ba4f4b4c4c3a55f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/120 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"batterydata/batterybert-cased-abstract\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2, torch_dtype=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\",\n",
    "                                  eval_strategy=\"epoch\",\n",
    "                                  num_train_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e849851642c84e24a6adf71bba854f72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca6fc854c2ec45fd9a968d2f2eb11a7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3411358892917633, 'eval_accuracy': 0.8833333333333333, 'eval_runtime': 0.9625, 'eval_samples_per_second': 124.681, 'eval_steps_per_second': 15.585, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "050d558b60bf4d05b1ee18213a20661a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.12239693850278854, 'eval_accuracy': 0.975, 'eval_runtime': 1.0173, 'eval_samples_per_second': 117.964, 'eval_steps_per_second': 14.745, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b1c8b5110924839b3b78a36377f2b05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2258392870426178, 'eval_accuracy': 0.925, 'eval_runtime': 1.0545, 'eval_samples_per_second': 113.8, 'eval_steps_per_second': 14.225, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3206a782742f4297a5ec6825b71596c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 9.412664803676307e-05, 'eval_accuracy': 1.0, 'eval_runtime': 1.0639, 'eval_samples_per_second': 112.792, 'eval_steps_per_second': 14.099, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a286bfcd294b433aaabbc4c000e545fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.201495853019878e-05, 'eval_accuracy': 1.0, 'eval_runtime': 1.0578, 'eval_samples_per_second': 113.445, 'eval_steps_per_second': 14.181, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d65c7bfac334d929dc345b602bdb71c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.880601409240626e-05, 'eval_accuracy': 1.0, 'eval_runtime': 1.0688, 'eval_samples_per_second': 112.277, 'eval_steps_per_second': 14.035, 'epoch': 6.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00fac60f347a45a18fb708d43ac93acb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.184379577054642e-05, 'eval_accuracy': 1.0, 'eval_runtime': 1.126, 'eval_samples_per_second': 106.571, 'eval_steps_per_second': 13.321, 'epoch': 7.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92d7c847d75e4be086884f4818bb12aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.8017449696781114e-05, 'eval_accuracy': 1.0, 'eval_runtime': 1.1477, 'eval_samples_per_second': 104.557, 'eval_steps_per_second': 13.07, 'epoch': 8.0}\n",
      "{'loss': 0.1242, 'grad_norm': 0.0012190280249342322, 'learning_rate': 8.333333333333334e-06, 'epoch': 8.33}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1ea2db18a41470e8467c56b6c48b662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.581124110496603e-05, 'eval_accuracy': 1.0, 'eval_runtime': 1.2715, 'eval_samples_per_second': 94.378, 'eval_steps_per_second': 11.797, 'epoch': 9.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "108166cb5da64ad98294f10286ca845e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.508112786221318e-05, 'eval_accuracy': 1.0, 'eval_runtime': 1.0549, 'eval_samples_per_second': 113.75, 'eval_steps_per_second': 14.219, 'epoch': 10.0}\n",
      "{'train_runtime': 144.3961, 'train_samples_per_second': 33.242, 'train_steps_per_second': 4.155, 'train_loss': 0.10353800328448415, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=600, training_loss=0.10353800328448415, metrics={'train_runtime': 144.3961, 'train_samples_per_second': 33.242, 'train_steps_per_second': 4.155, 'total_flos': 1262933065728000.0, 'train_loss': 0.10353800328448415, 'epoch': 10.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"batterybert-cased-abstract_finetuned_600\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"text-classification\", model=\"batterybert-cased-abstract_finetuned_600\", tokenizer=tokenizer, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    }
   ],
   "source": [
    "val_path = r'C:\\Users\\Subways-Sun\\OneDrive\\Documents\\GitHub\\sodium-ion-batteries\\data_annotated\\annotated_data_openai_1.json'\n",
    "with open(val_path, 'r', encoding='utf-8') as f:\n",
    "    val_data = json.load(f)\n",
    "\n",
    "label_bert = []\n",
    "score_bert = []\n",
    "for i in range(len(val_data[\"text\"])):\n",
    "    val_label = classifier(val_data[\"text\"][i][:512])\n",
    "    if val_label[0][\"label\"] == \"battery\":\n",
    "        label_bert.append(1)\n",
    "        score_bert.append(val_label[0][\"score\"])\n",
    "    elif val_label[0][\"label\"] == \"non-battery\":\n",
    "        label_bert.append(0)\n",
    "        score_bert.append(val_label[0][\"score\"])\n",
    "\n",
    "val_data[\"label_bert\"] = label_bert\n",
    "val_data[\"score_bert\"] = score_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No\tAnno\tOpenAI\tBERT\tBERT Score\n",
      "7\t0\t1\t1\t0.7103307843208313\n",
      "11\t1\t1\t0\t0.9999046325683594\n",
      "12\t1\t1\t0\t0.852022647857666\n",
      "19\t1\t1\t0\t0.9999538660049438\n",
      "21\t0\t1\t0\t0.9999834299087524\n",
      "27\t1\t1\t0\t0.9998410940170288\n",
      "34\t0\t1\t0\t0.9999847412109375\n",
      "36\t0\t1\t0\t0.999985933303833\n",
      "39\t1\t1\t0\t0.9999593496322632\n",
      "47\t1\t1\t0\t0.9999285936355591\n",
      "53\t0\t1\t0\t0.9999818801879883\n",
      "59\t1\t1\t0\t0.9990074038505554\n",
      "79\t0\t1\t0\t0.9999827146530151\n",
      "80\t0\t1\t0\t0.9999306201934814\n",
      "82\t1\t1\t0\t0.9997178912162781\n",
      "88\t1\t1\t0\t0.999763548374176\n",
      "90\t1\t1\t0\t0.9302987456321716\n",
      "92\t1\t1\t0\t0.999806821346283\n",
      "97\t1\t1\t0\t0.9949029684066772\n",
      "99\t0\t1\t0\t0.9966214895248413\n",
      "OpenAI True Positive: 87\n",
      "OpenAI True Negative: 5\n",
      "OpenAI False Positive: 8\n",
      "OpenAI False Negative: 0\n",
      "Bert True Positive: 75\n",
      "Bert True Negative: 12\n",
      "Bert False Positive: 1\n",
      "Bert False Negative: 12\n"
     ]
    }
   ],
   "source": [
    "label_openai = val_data[\"label_openai\"]\n",
    "label_annotated = val_data[\"label_annotated\"]\n",
    "print(f\"No\\tAnno\\tOpenAI\\tBERT\\tBERT Score\")\n",
    "\n",
    "openai_tp = 0\n",
    "openai_tn = 0\n",
    "openai_fp = 0\n",
    "openai_fn = 0\n",
    "bert_tp = 0\n",
    "bert_tn = 0\n",
    "bert_fp = 0\n",
    "bert_fn = 0\n",
    "\n",
    "for i in range(len(label_bert)):\n",
    "    if (label_bert[i] + label_openai[i] + label_annotated[i] != 3) and (label_bert[i] + label_openai[i] + label_annotated[i] != 0):\n",
    "        print(f\"{i}\\t{label_annotated[i]}\\t{label_openai[i]}\\t{label_bert[i]}\\t{score_bert[i]}\")\n",
    "        if label_bert[i] == 1 and label_annotated[i] == 0:\n",
    "            bert_fp += 1\n",
    "        elif label_bert[i] == 0 and label_annotated[i] == 1:\n",
    "            bert_fn += 1\n",
    "        if label_openai[i] == 1 and label_annotated[i] == 0:\n",
    "            openai_fp += 1\n",
    "        elif label_openai[i] == 0 and label_annotated[i] == 1:\n",
    "            openai_fn += 1\n",
    "    if label_bert[i] == 1 and label_annotated[i] == 1:\n",
    "        bert_tp += 1\n",
    "    if label_bert[i] == 0 and label_annotated[i] == 0:\n",
    "        bert_tn += 1\n",
    "    if label_openai[i] == 1 and label_annotated[i] == 1:\n",
    "        openai_tp += 1\n",
    "    if label_openai[i] == 0 and label_annotated[i] == 0:\n",
    "        openai_tn += 1\n",
    "        \n",
    "print(f\"OpenAI True Positive: {openai_tp}\")\n",
    "print(f\"OpenAI True Negative: {openai_tn}\")\n",
    "print(f\"OpenAI False Positive: {openai_fp}\")\n",
    "print(f\"OpenAI False Negative: {openai_fn}\")\n",
    "print(f\"Bert True Positive: {bert_tp}\")\n",
    "print(f\"Bert True Negative: {bert_tn}\")\n",
    "print(f\"Bert False Positive: {bert_fp}\")\n",
    "print(f\"Bert False Negative: {bert_fn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_path = r'C:\\Users\\Subways-Sun\\OneDrive\\Documents\\GitHub\\sodium-ion-batteries\\data_annotated\\annotated_data_openai.json'\n",
    "with open(val_path, 'r', encoding='utf-8') as f:\n",
    "    val_data = json.load(f)\n",
    "\n",
    "label_bert = []\n",
    "score_bert = []\n",
    "for i in range(len(val_data[\"text\"])):\n",
    "    val_label = classifier(val_data[\"text\"][i][:512])\n",
    "    if val_label[0][\"label\"] == \"battery\":\n",
    "        label_bert.append(1)\n",
    "        score_bert.append(val_label[0][\"score\"])\n",
    "    elif val_label[0][\"label\"] == \"non-battery\":\n",
    "        label_bert.append(0)\n",
    "        score_bert.append(val_label[0][\"score\"])\n",
    "\n",
    "val_data[\"label_bert\"] = label_bert\n",
    "val_data[\"score_bert\"] = score_bert\n",
    "\n",
    "# result_path = r'C:\\Users\\Subways-Sun\\OneDrive\\Documents\\GitHub\\sodium-ion-batteries\\data_annotated\\annotated_data_openai_bert.json'\n",
    "# with open(result_path, 'w', encoding='utf-8') as f:\n",
    "#     json.dump(val_data, f, indent=4, ensure_ascii=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No\tAnno\tOpenAI\tBERT\tBERT Score\n",
      "1\t1\t1\t0\t0.9949029684066772\n",
      "2\t1\t1\t0\t0.999806821346283\n",
      "4\t0\t1\t1\t0.9998987913131714\n",
      "5\t0\t1\t0\t0.9999827146530151\n",
      "8\t1\t0\t1\t0.9999698400497437\n",
      "15\t1\t1\t0\t0.9999538660049438\n",
      "22\t1\t0\t0\t0.999763548374176\n",
      "29\t1\t1\t0\t0.9998410940170288\n",
      "40\t1\t1\t0\t0.9302987456321716\n",
      "51\t1\t1\t0\t0.9999285936355591\n",
      "59\t1\t1\t0\t0.9997178912162781\n",
      "63\t0\t1\t0\t0.9999818801879883\n",
      "68\t1\t0\t1\t0.9999468326568604\n",
      "80\t1\t1\t0\t0.9999046325683594\n",
      "85\t1\t1\t0\t0.9990074038505554\n",
      "90\t0\t0\t1\t0.7103307843208313\n",
      "95\t0\t1\t0\t0.9999847412109375\n",
      "103\t0\t1\t0\t0.999985933303833\n",
      "112\t0\t1\t1\t0.9945092797279358\n",
      "115\t1\t1\t0\t0.852022647857666\n",
      "135\t0\t1\t0\t0.9966214895248413\n",
      "136\t0\t1\t1\t0.9999493360519409\n",
      "137\t0\t1\t0\t0.9999306201934814\n",
      "139\t1\t1\t0\t0.9999593496322632\n",
      "OpenAI True Positive: 84\n",
      "OpenAI True Negative: 54\n",
      "OpenAI False Positive: 9\n",
      "OpenAI False Negative: 3\n",
      "Bert True Positive: 75\n",
      "Bert True Negative: 59\n",
      "Bert False Positive: 4\n",
      "Bert False Negative: 12\n"
     ]
    }
   ],
   "source": [
    "label_openai = val_data[\"label_openai\"]\n",
    "label_annotated = val_data[\"label_annotated\"]\n",
    "print(f\"No\\tAnno\\tOpenAI\\tBERT\\tBERT Score\")\n",
    "\n",
    "openai_tp = 0\n",
    "openai_tn = 0\n",
    "openai_fp = 0\n",
    "openai_fn = 0\n",
    "bert_tp = 0\n",
    "bert_tn = 0\n",
    "bert_fp = 0\n",
    "bert_fn = 0\n",
    "\n",
    "for i in range(len(label_bert)):\n",
    "    if (label_bert[i] + label_openai[i] + label_annotated[i] != 3) and (label_bert[i] + label_openai[i] + label_annotated[i] != 0):\n",
    "        print(f\"{i}\\t{label_annotated[i]}\\t{label_openai[i]}\\t{label_bert[i]}\\t{score_bert[i]}\")\n",
    "        if label_bert[i] == 1 and label_annotated[i] == 0:\n",
    "            bert_fp += 1\n",
    "        elif label_bert[i] == 0 and label_annotated[i] == 1:\n",
    "            bert_fn += 1\n",
    "        if label_openai[i] == 1 and label_annotated[i] == 0:\n",
    "            openai_fp += 1\n",
    "        elif label_openai[i] == 0 and label_annotated[i] == 1:\n",
    "            openai_fn += 1\n",
    "    if label_bert[i] == 1 and label_annotated[i] == 1:\n",
    "        bert_tp += 1\n",
    "    if label_bert[i] == 0 and label_annotated[i] == 0:\n",
    "        bert_tn += 1\n",
    "    if label_openai[i] == 1 and label_annotated[i] == 1:\n",
    "        openai_tp += 1\n",
    "    if label_openai[i] == 0 and label_annotated[i] == 0:\n",
    "        openai_tn += 1\n",
    "        \n",
    "print(f\"OpenAI True Positive: {openai_tp}\")\n",
    "print(f\"OpenAI True Negative: {openai_tn}\")\n",
    "print(f\"OpenAI False Positive: {openai_fp}\")\n",
    "print(f\"OpenAI False Negative: {openai_fn}\")\n",
    "print(f\"Bert True Positive: {bert_tp}\")\n",
    "print(f\"Bert True Negative: {bert_tn}\")\n",
    "print(f\"Bert False Positive: {bert_fp}\")\n",
    "print(f\"Bert False Negative: {bert_fn}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
