{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "data_path = r'C:\\Users\\Subways-Sun\\OneDrive\\Documents\\GitHub\\sodium-ion-batteries\\data_annotated\\search_20241106-223705_sodium+ion+battery+anode-sodium+ion+battery+cathode-sodium+ion+battery+electrode_annotated_rephrased.json'\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "texts = []\n",
    "labels_raw = []\n",
    "\n",
    "for i in data:\n",
    "    texts.append(i[\"text\"])\n",
    "    labels_raw.append(i[\"label_int\"])\n",
    "\n",
    "labels = []\n",
    "for i in labels_raw:\n",
    "    if i == 0:\n",
    "        labels.append(1)\n",
    "    elif i == 1:\n",
    "        labels.append(0)\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    texts,\n",
    "    labels,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_dataset = Dataset.from_dict({\n",
    "    'text': train_texts,\n",
    "    'labels': train_labels\n",
    "})\n",
    "\n",
    "val_dataset = Dataset.from_dict({\n",
    "    'text': val_texts,\n",
    "    'labels': val_labels\n",
    "})\n",
    "\n",
    "raw_datasets = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': val_dataset\n",
    "})\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'labels'],\n",
      "        num_rows: 320\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'labels'],\n",
      "        num_rows: 80\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(raw_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ba5f58ea8374a36b1ac936c4dcff141",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/320 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccb9f5c18be647e28a569b1e6b785f44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/80 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"batterydata/batterybert-cased-abstract\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2, torch_dtype=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\",\n",
    "                                  eval_strategy=\"epoch\",\n",
    "                                  num_train_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a805295b47494fff961b61639371977c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "418cb5b09adc4a57acce728b930ca239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.38305428624153137, 'eval_accuracy': 0.9375, 'eval_runtime': 0.6628, 'eval_samples_per_second': 120.7, 'eval_steps_per_second': 15.087, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb4df0e1e1ea413bac7cb9212826eb61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2910386323928833, 'eval_accuracy': 0.925, 'eval_runtime': 0.6807, 'eval_samples_per_second': 117.528, 'eval_steps_per_second': 14.691, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c66d2e1d899c4750bcc0d10a7ad3021f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.18304702639579773, 'eval_accuracy': 0.9625, 'eval_runtime': 0.6928, 'eval_samples_per_second': 115.467, 'eval_steps_per_second': 14.433, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a83e437416b84ba593d749771fa5f3c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.21540328860282898, 'eval_accuracy': 0.95, 'eval_runtime': 0.7331, 'eval_samples_per_second': 109.121, 'eval_steps_per_second': 13.64, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4866f2fbfb2c43a5b245e7bc455dc4b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.17034180462360382, 'eval_accuracy': 0.9625, 'eval_runtime': 0.7069, 'eval_samples_per_second': 113.168, 'eval_steps_per_second': 14.146, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6412113c8de54c88bf002d9840ec9ab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.20277062058448792, 'eval_accuracy': 0.95, 'eval_runtime': 0.6987, 'eval_samples_per_second': 114.497, 'eval_steps_per_second': 14.312, 'epoch': 6.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11c1e7434610480c9e23a1c515903fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.20584681630134583, 'eval_accuracy': 0.95, 'eval_runtime': 0.6816, 'eval_samples_per_second': 117.365, 'eval_steps_per_second': 14.671, 'epoch': 7.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "441e243f380a46eea4fcbf57840b58e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2196522206068039, 'eval_accuracy': 0.95, 'eval_runtime': 0.6849, 'eval_samples_per_second': 116.798, 'eval_steps_per_second': 14.6, 'epoch': 8.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d5ce863098b4cc1898004045bfa8ae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2087225466966629, 'eval_accuracy': 0.95, 'eval_runtime': 0.6979, 'eval_samples_per_second': 114.635, 'eval_steps_per_second': 14.329, 'epoch': 9.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59884c045a8f423a8ceb764c4102b692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.20584864914417267, 'eval_accuracy': 0.95, 'eval_runtime': 0.6599, 'eval_samples_per_second': 121.228, 'eval_steps_per_second': 15.153, 'epoch': 10.0}\n",
      "{'train_runtime': 91.5542, 'train_samples_per_second': 34.952, 'train_steps_per_second': 4.369, 'train_loss': 0.16644613265991212, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=400, training_loss=0.16644613265991212, metrics={'train_runtime': 91.5542, 'train_samples_per_second': 34.952, 'train_steps_per_second': 4.369, 'total_flos': 841955377152000.0, 'train_loss': 0.16644613265991212, 'epoch': 10.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"batterybert-cased-abstract_finetuned_400\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"text-classification\", model=\"batterybert-cased-abstract_finetuned_400\", tokenizer=tokenizer, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    }
   ],
   "source": [
    "val_path = r'C:\\Users\\Subways-Sun\\OneDrive\\Documents\\GitHub\\sodium-ion-batteries\\data_annotated\\annotated_data_openai_1.json'\n",
    "with open(val_path, 'r', encoding='utf-8') as f:\n",
    "    val_data = json.load(f)\n",
    "\n",
    "label_bert = []\n",
    "score_bert = []\n",
    "for i in range(len(val_data[\"text\"])):\n",
    "    val_label = classifier(val_data[\"text\"][i][:512])\n",
    "    if val_label[0][\"label\"] == \"battery\":\n",
    "        label_bert.append(1)\n",
    "        score_bert.append(val_label[0][\"score\"])\n",
    "    elif val_label[0][\"label\"] == \"non-battery\":\n",
    "        label_bert.append(0)\n",
    "        score_bert.append(val_label[0][\"score\"])\n",
    "\n",
    "val_data[\"label_bert\"] = label_bert\n",
    "val_data[\"score_bert\"] = score_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No\tAnno\tOpenAI\tBERT\tBERT Score\n",
      "7\t0\t1\t0\t0.9998679161071777\n",
      "14\t0\t0\t1\t0.9926759600639343\n",
      "21\t0\t1\t0\t0.9998675584793091\n",
      "26\t1\t1\t0\t0.9979070425033569\n",
      "27\t1\t1\t0\t0.9998754262924194\n",
      "34\t0\t1\t0\t0.9998750686645508\n",
      "36\t0\t1\t0\t0.9998751878738403\n",
      "39\t1\t1\t0\t0.9998252987861633\n",
      "42\t1\t1\t0\t0.960843563079834\n",
      "45\t1\t1\t0\t0.9922792911529541\n",
      "47\t1\t1\t0\t0.999674916267395\n",
      "53\t0\t1\t0\t0.9998691082000732\n",
      "75\t0\t0\t1\t0.993808925151825\n",
      "79\t0\t1\t0\t0.9998757839202881\n",
      "80\t0\t1\t0\t0.9997312426567078\n",
      "83\t0\t0\t1\t0.9937708973884583\n",
      "86\t1\t1\t0\t0.9607234597206116\n",
      "87\t1\t1\t0\t0.9994949102401733\n",
      "89\t1\t1\t0\t0.9998729228973389\n",
      "99\t0\t1\t0\t0.9998770952224731\n",
      "OpenAI True Positive: 87\n",
      "OpenAI True Negative: 5\n",
      "OpenAI False Positive: 8\n",
      "OpenAI False Negative: 0\n",
      "Bert True Positive: 78\n",
      "Bert True Negative: 10\n",
      "Bert False Positive: 3\n",
      "Bert False Negative: 9\n"
     ]
    }
   ],
   "source": [
    "label_openai = val_data[\"label_openai\"]\n",
    "label_annotated = val_data[\"label_annotated\"]\n",
    "print(f\"No\\tAnno\\tOpenAI\\tBERT\\tBERT Score\")\n",
    "\n",
    "openai_tp = 0\n",
    "openai_tn = 0\n",
    "openai_fp = 0\n",
    "openai_fn = 0\n",
    "bert_tp = 0\n",
    "bert_tn = 0\n",
    "bert_fp = 0\n",
    "bert_fn = 0\n",
    "\n",
    "for i in range(len(label_bert)):\n",
    "    if (label_bert[i] + label_openai[i] + label_annotated[i] != 3) and (label_bert[i] + label_openai[i] + label_annotated[i] != 0):\n",
    "        print(f\"{i}\\t{label_annotated[i]}\\t{label_openai[i]}\\t{label_bert[i]}\\t{score_bert[i]}\")\n",
    "        if label_bert[i] == 1 and label_annotated[i] == 0:\n",
    "            bert_fp += 1\n",
    "        elif label_bert[i] == 0 and label_annotated[i] == 1:\n",
    "            bert_fn += 1\n",
    "        if label_openai[i] == 1 and label_annotated[i] == 0:\n",
    "            openai_fp += 1\n",
    "        elif label_openai[i] == 0 and label_annotated[i] == 1:\n",
    "            openai_fn += 1\n",
    "    if label_bert[i] == 1 and label_annotated[i] == 1:\n",
    "        bert_tp += 1\n",
    "    if label_bert[i] == 0 and label_annotated[i] == 0:\n",
    "        bert_tn += 1\n",
    "    if label_openai[i] == 1 and label_annotated[i] == 1:\n",
    "        openai_tp += 1\n",
    "    if label_openai[i] == 0 and label_annotated[i] == 0:\n",
    "        openai_tn += 1\n",
    "        \n",
    "print(f\"OpenAI True Positive: {openai_tp}\")\n",
    "print(f\"OpenAI True Negative: {openai_tn}\")\n",
    "print(f\"OpenAI False Positive: {openai_fp}\")\n",
    "print(f\"OpenAI False Negative: {openai_fn}\")\n",
    "print(f\"Bert True Positive: {bert_tp}\")\n",
    "print(f\"Bert True Negative: {bert_tn}\")\n",
    "print(f\"Bert False Positive: {bert_fp}\")\n",
    "print(f\"Bert False Negative: {bert_fn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_path = r'C:\\Users\\Subways-Sun\\OneDrive\\Documents\\GitHub\\sodium-ion-batteries\\data_annotated\\annotated_data_openai.json'\n",
    "with open(val_path, 'r', encoding='utf-8') as f:\n",
    "    val_data = json.load(f)\n",
    "\n",
    "label_bert = []\n",
    "score_bert = []\n",
    "for i in range(len(val_data[\"text\"])):\n",
    "    val_label = classifier(val_data[\"text\"][i][:512])\n",
    "    if val_label[0][\"label\"] == \"battery\":\n",
    "        label_bert.append(1)\n",
    "        score_bert.append(val_label[0][\"score\"])\n",
    "    elif val_label[0][\"label\"] == \"non-battery\":\n",
    "        label_bert.append(0)\n",
    "        score_bert.append(val_label[0][\"score\"])\n",
    "\n",
    "val_data[\"label_bert\"] = label_bert\n",
    "val_data[\"score_bert\"] = score_bert\n",
    "\n",
    "# result_path = r'C:\\Users\\Subways-Sun\\OneDrive\\Documents\\GitHub\\sodium-ion-batteries\\data_annotated\\annotated_data_openai_bert.json'\n",
    "# with open(result_path, 'w', encoding='utf-8') as f:\n",
    "#     json.dump(val_data, f, indent=4, ensure_ascii=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No\tAnno\tOpenAI\tBERT\tBERT Score\n",
      "4\t0\t1\t0\t0.9992319345474243\n",
      "5\t0\t1\t0\t0.9998757839202881\n",
      "7\t0\t0\t1\t0.9926759600639343\n",
      "8\t1\t0\t1\t0.9938077330589294\n",
      "9\t0\t0\t1\t0.9938070178031921\n",
      "11\t1\t1\t0\t0.9998729228973389\n",
      "12\t0\t0\t1\t0.9937630295753479\n",
      "13\t1\t1\t0\t0.9607234597206116\n",
      "14\t0\t0\t1\t0.9938378930091858\n",
      "17\t0\t0\t1\t0.9938337802886963\n",
      "20\t0\t0\t1\t0.9938110709190369\n",
      "22\t1\t0\t1\t0.9938226938247681\n",
      "25\t0\t0\t1\t0.9938147068023682\n",
      "29\t1\t1\t0\t0.9998754262924194\n",
      "36\t0\t0\t1\t0.9937883019447327\n",
      "44\t0\t0\t1\t0.9938296675682068\n",
      "46\t0\t0\t1\t0.9938139915466309\n",
      "49\t0\t0\t1\t0.993808925151825\n",
      "51\t1\t1\t0\t0.999674916267395\n",
      "53\t0\t0\t1\t0.9938202500343323\n",
      "58\t0\t0\t1\t0.992300271987915\n",
      "60\t0\t0\t1\t0.9936913251876831\n",
      "62\t1\t1\t0\t0.9979070425033569\n",
      "63\t0\t1\t0\t0.9998691082000732\n",
      "64\t0\t0\t1\t0.9938437938690186\n",
      "66\t0\t0\t1\t0.9937887787818909\n",
      "68\t1\t0\t1\t0.9800814390182495\n",
      "75\t0\t0\t1\t0.993826687335968\n",
      "76\t0\t0\t1\t0.9098774790763855\n",
      "79\t0\t0\t1\t0.9915518760681152\n",
      "87\t1\t1\t0\t0.960843563079834\n",
      "88\t0\t0\t1\t0.9937971830368042\n",
      "94\t0\t0\t1\t0.9935727119445801\n",
      "95\t0\t1\t0\t0.9998750686645508\n",
      "97\t0\t0\t1\t0.9933725595474243\n",
      "98\t1\t1\t0\t0.9922792911529541\n",
      "99\t0\t0\t1\t0.9935950636863708\n",
      "101\t0\t0\t1\t0.9937708973884583\n",
      "102\t0\t0\t1\t0.9938310384750366\n",
      "103\t0\t1\t0\t0.9998751878738403\n",
      "108\t0\t0\t1\t0.9938056468963623\n",
      "112\t0\t1\t1\t0.9937991499900818\n",
      "113\t0\t0\t1\t0.9938027858734131\n",
      "114\t0\t0\t1\t0.9539491534233093\n",
      "120\t0\t0\t1\t0.9938228130340576\n",
      "121\t0\t0\t1\t0.9931908249855042\n",
      "122\t0\t0\t1\t0.993770182132721\n",
      "134\t0\t0\t1\t0.9938242435455322\n",
      "135\t0\t1\t0\t0.9998770952224731\n",
      "136\t0\t1\t1\t0.9938305020332336\n",
      "137\t0\t1\t0\t0.9997312426567078\n",
      "139\t1\t1\t0\t0.9998252987861633\n",
      "143\t0\t0\t1\t0.9938324689865112\n",
      "149\t1\t1\t0\t0.9994949102401733\n",
      "OpenAI True Positive: 84\n",
      "OpenAI True Negative: 54\n",
      "OpenAI False Positive: 9\n",
      "OpenAI False Negative: 3\n",
      "Bert True Positive: 78\n",
      "Bert True Negative: 28\n",
      "Bert False Positive: 35\n",
      "Bert False Negative: 9\n"
     ]
    }
   ],
   "source": [
    "label_openai = val_data[\"label_openai\"]\n",
    "label_annotated = val_data[\"label_annotated\"]\n",
    "print(f\"No\\tAnno\\tOpenAI\\tBERT\\tBERT Score\")\n",
    "\n",
    "openai_tp = 0\n",
    "openai_tn = 0\n",
    "openai_fp = 0\n",
    "openai_fn = 0\n",
    "bert_tp = 0\n",
    "bert_tn = 0\n",
    "bert_fp = 0\n",
    "bert_fn = 0\n",
    "\n",
    "for i in range(len(label_bert)):\n",
    "    if (label_bert[i] + label_openai[i] + label_annotated[i] != 3) and (label_bert[i] + label_openai[i] + label_annotated[i] != 0):\n",
    "        print(f\"{i}\\t{label_annotated[i]}\\t{label_openai[i]}\\t{label_bert[i]}\\t{score_bert[i]}\")\n",
    "        if label_bert[i] == 1 and label_annotated[i] == 0:\n",
    "            bert_fp += 1\n",
    "        elif label_bert[i] == 0 and label_annotated[i] == 1:\n",
    "            bert_fn += 1\n",
    "        if label_openai[i] == 1 and label_annotated[i] == 0:\n",
    "            openai_fp += 1\n",
    "        elif label_openai[i] == 0 and label_annotated[i] == 1:\n",
    "            openai_fn += 1\n",
    "    if label_bert[i] == 1 and label_annotated[i] == 1:\n",
    "        bert_tp += 1\n",
    "    if label_bert[i] == 0 and label_annotated[i] == 0:\n",
    "        bert_tn += 1\n",
    "    if label_openai[i] == 1 and label_annotated[i] == 1:\n",
    "        openai_tp += 1\n",
    "    if label_openai[i] == 0 and label_annotated[i] == 0:\n",
    "        openai_tn += 1\n",
    "        \n",
    "print(f\"OpenAI True Positive: {openai_tp}\")\n",
    "print(f\"OpenAI True Negative: {openai_tn}\")\n",
    "print(f\"OpenAI False Positive: {openai_fp}\")\n",
    "print(f\"OpenAI False Negative: {openai_fn}\")\n",
    "print(f\"Bert True Positive: {bert_tp}\")\n",
    "print(f\"Bert True Negative: {bert_tn}\")\n",
    "print(f\"Bert False Positive: {bert_fp}\")\n",
    "print(f\"Bert False Negative: {bert_fn}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
